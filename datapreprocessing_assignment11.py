# -*- coding: utf-8 -*-
"""DataPreprocessing_Assignment11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nxWlPW7_9iOpQawdIvIIwbr2T0mM3eGu
"""

#Data.csv

"""**Step 1: Importing the libraries**"""

import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

"""**Step 2: Importing dataset**"""

data=pd.read_csv('Data.csv')
data

"""**Step 3: Handling the missing data**"""

data['Age'].fillna(int(data['Age'].mean()),inplace=True)
data['Salary'].fillna(int(data['Salary'].mean()),inplace=True)
data.info()

"""**Step 4: Encoding categorical data**"""

label_encode=LabelEncoder()
data['Purchased']=label_encode.fit_transform(data['Purchased'])

"""**Step 5: Creating a dummy variable**"""

data=pd.get_dummies(data)
data

"""**Step 6: Splitting the datasets into training sets and Test sets**"""

x=data[['Age','Salary','Country_France','Country_Germany','Country_Spain']]
y=data[['Purchased']]
X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=1)

"""**Step 7: Feature Scaling**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train) 
X_test = sc.transform(X_test)

